# Awesome-Cross-modal-Reasoning-with-Large-Language-Models











# Awesome Papers

## Multimodal Fusion Engine
|  Model  |   Paper  |   Code   |   Demo   |   Data   |
|:--------|:--------:|:--------:|:--------:|:--------:|
| ![Star](https://img.shields.io/github/stars/ttengwang/Caption-Anything.svg?style=social&label=Star) CAT | <br> [**Caption Anything: Interactive Image Description with Diverse Multimodal Controls**](https://arxiv.org/pdf/2305.02677) <br>  | [Github](https://github.com/ttengwang/Caption-Anything) | [Demo](https://huggingface.co/spaces/TencentARC/Caption-Anything) |2023-05-04|
| ![Star](https://img.shields.io/github/stars/guilk/KAT.svg?style=social&label=Star) KAT | <br> [**KAT: A Knowledge Augmented Transformer for Vision-and-Language**](https://arxiv.org/abs/2112.08614) <br>  | [Github](https://github.com/guilk/KAT) | [Demo]() |2022-05|

| ![Star](https://img.shields.io/github/stars/yuanze-lin/REVIVE.svg?style=social&label=Star) REVIVE | <br> [**REVIVE: Regional Visual Representation Matters in Knowledge-Based Visual Question Answering**](https://arxiv.org/abs/2206.01201) <br>  | [Github](https://github.com/yuanze-lin/REVIVE) | [Demo](  ) |2022-06|
| ![Star](https://img.shields.io/github/stars/microsoft/TaskMatrix.svg?style=social&label=Star) Visual ChatGPT  | <br>[**Visual ChatGPT: Talking, Drawing and Editing with Visual Foundation Models**](https://arxiv.org/pdf/2303.04671.pdf)<br>  | [Github](https://github.com/microsoft/TaskMatrix) | [Demo](https://huggingface.co/spaces/microsoft/visual_chatgpt) |2023-03|
| ![Star](https://img.shields.io/github/stars/kyegomez/PALM-E.svg?style=social&label=Star) PaLM-E | <br> [**PaLM-E: An Embodied Multimodal Language Model**](https://arxiv.org/pdf/2303.03378.pdf) <br>  | [Github](https://github.com/kyegomez/PALM-E) | [Demo](https://palm-e.github.io/#demo) |2022-06|
| ![Star](https://img.shields.io/github/stars/j-min/VL-T5.svg?style=social&label=Star)VL-T5  | <br> [**Unifying Vision-and-Language Tasks via Text Generation**](https://arxiv.org/abs/2102.02779) <br>  | [Github](https://github.com/j-min/VL-T5) | [Demo](https://replicate.com/j-min/vl-t5) |2021-5|


| ![Star](https://img.shields.io/github/stars/***************.svg?style=social&label=Star)  | <br> [** **](   ) <br>  | [Github](   ) | [Demo](  ) |20-|













| ![Star](https://img.shields.io/github/stars/***************.svg?style=social&label=Star)  | <br> [** **](   ) <br>  | [Github](   ) | [Demo](  ) |20-|
| ![Star](https://img.shields.io/github/stars/***************.svg?style=social&label=Star)  | <br> [** **](   ) <br>  | [Github](   ) | [Demo](  ) |20-|
| ![Star](https://img.shields.io/github/stars/***************.svg?style=social&label=Star)  | <br> [** **](   ) <br>  | [Github](   ) | [Demo](  ) |20-|
| ![Star](https://img.shields.io/github/stars/***************.svg?style=social&label=Star)  | <br> [** **](   ) <br>  | [Github](   ) | [Demo](  ) |20-|
| ![Star](https://img.shields.io/github/stars/***************.svg?style=social&label=Star)  | <br> [** **](   ) <br>  | [Github](   ) | [Demo](  ) |20-|





|  <br>  <br> | arXiv | -08 | [Github]() | [Demo]() |


| ![Star](https://img.shields.io/github/stars/)  | <br> [** **](   ) <br>  | [Github](   ) | [Demo](  ) |20--|






| ![Star](https://img.shields.io/github/stars/ttengwang/Caption-Anything.svg?style=social&label=Star) <br> [**Caption Anything: Interactive Image Description with Diverse Multimodal Controls**](https://arxiv.org/pdf/2305.02677.pdf) <br> | arXiv | 2023-05-04 | [Github](https://github.com/ttengwang/Caption-Anything) | [Demo](https://huggingface.co/spaces/TencentARC/Caption-Anything) |



| ![Star](https://img.shields.io/github/stars/X-PLUG/mPLUG-Owl.svg?style=social&label=Star) <br> [**mPLUG-Owl3: Towards Long Image-Sequence Understanding in Multi-Modal Large Language Models**](https://www.arxiv.org/pdf/2408.04840) <br> | arXiv | 2024-08-09 | [Github](https://github.com/X-PLUG/mPLUG-Owl) | - |
| ![Star](https://img.shields.io/github/stars/VITA-MLLM/VITA.svg?style=social&label=Star) <br> [**VITA: Towards Open-Source Interactive Omni Multimodal LLM**](https://arxiv.org/pdf/2408.05211) <br> | arXiv | 2024-08-09 | [Github](https://github.com/VITA-MLLM/VITA) | - | 
| ![Star](https://img.shields.io/github/stars/LLaVA-VL/LLaVA-NeXT.svg?style=social&label=Star) <br> [**LLaVA-OneVision: Easy Visual Task Transfer**](https://arxiv.org/pdf/2408.03326) <br> | arXiv | 2024-08-06 | [Github](https://github.com/LLaVA-VL/LLaVA-NeXT) | [Demo](https://llava-onevision.lmms-lab.com) | 



